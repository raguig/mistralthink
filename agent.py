import json
import re
from typing import Annotated, Sequence, TypedDict

from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage
from langgraph.graph import END, StateGraph
from langgraph.graph.message import add_messages

from config import CRITIC_MODEL, MODEL
from mistral_client import collect_streamed_response, safe_chat_complete, safe_chat_stream
from tools import execute_tool_by_name_and_args, infer_required_tools_from_plan, tools
from utils import is_math_query, normalize_reply_content


class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    summary: str
    image_data: str
    plan: str
    needs_retry: bool
    retry_count: int
    required_tools: list[str]


def is_internal_control_message(text: str) -> bool:
    t = (text or "").strip().lower()
    internal_prefixes = [
        "continue and finish the remaining steps now.",
        "revise and improve the previous answer based on this critique",
        "revise the answer for a pure math query.",
        "revise with minimal tool usage.",
        "revise the answer and remove external links/references.",
    ]
    return any(t.startswith(prefix) for prefix in internal_prefixes)


def planner_node(state: AgentState):
    summary = state.get("summary", "New conversation")
    query = state["messages"][-1].content if state["messages"] else ""
    if isinstance(query, list):
        query = normalize_reply_content(query)

    planning_text = (
        "You are a helpful multimodal agent. Create a minimal step-by-step plan.\n"
        "IMPORTANT RULES:\n"
        "- For pure math questions: use ONLY calculator. No web_search, no code_interpreter.\n"
        "- For coding/plotting requests: use ONLY code_interpreter.\n"
        "- For fact/news/current-events requests: use ONLY web_search.\n"
        "- NEVER suggest web_search for arithmetic or symbolic math.\n"
        "- NEVER suggest code_interpreter just to verify calculator output.\n"
        "- For simple requests, use 1-2 steps maximum.\n\n"
        f"Conversation summary: {summary or 'New conversation'}\n"
        f"User query: {query}\n\n"
        "Output ONLY the plan as numbered steps."
    )
    try:
        plan = safe_chat_complete(
            model=MODEL,
            messages=[{"role": "user", "content": planning_text}],
            max_tokens=300,
            temperature=0.2,
        ).choices[0].message.content
        plan = normalize_reply_content(plan)
    except Exception:
        plan = (
            "1. Analyze image trends.\n"
            "2. Use web_search for recent/similar data.\n"
            "3. Use code_interpreter to produce and verify improved visualization.\n"
            "4. Summarize findings with tool evidence."
        )

    return {"plan": plan}


def used_tools_from_messages(messages):
    used = []
    for msg in messages:
        if isinstance(msg, ToolMessage):
            name = getattr(msg, "name", "")
            if name:
                used.append(name)
    return used


def build_mistral_messages(state: AgentState):
    messages = state.get("messages", [])
    summary = state.get("summary", "")
    plan = state.get("plan", "")
    image_data = state.get("image_data", "")

    system_prompt = (
        "You MUST follow the plan step-by-step. Do not skip or combine steps unless explicitly allowed.\n"
        "Follow the plan and complete the task end-to-end in this turn. "
        "Do not say you will do a step later; either do it now with tool calls or explain the concrete tool error.\n"
        "Do not print raw tool-call JSON in your final answer.\n"
        "If an image is attached, do not claim the image is unavailable; analyze it directly.\n"
        "If asked to analyze trends, include a concise trend analysis. "
        "If asked to search recent/similar data, perform web_search and cite key findings. "
        "If asked to code and verify, run code_interpreter and report execution status.\n\n"
        "Never invent or reference tools that don't exist. "
        "Available tools are ONLY: calculator, web_search, code_interpreter. "
        "For image description, use your vision capabilities directly - no tools needed.\n\n"
        "CRITICAL: Never use hypothetical, placeholder, or made-up data. "
        "If a tool returns no usable data, say so explicitly and stop. "
        "Do not proceed with fabricated numbers.\n\n"
        "If the request is a simple math calculation, answer in 1-2 lines with the final value. "
        "Do not add long explanations.\n\n"
        "If a plot/image was generated by a tool, do NOT include markdown image embeds "
        "(e.g., ![...](attachment:...)) in the text response. "
        "The UI will display the image separately. Keep the text response short.\n\n"
        "Output requirements for final answer:\n"
        "1) If web_search was used, include source links from tool output.\n"
        "2) Keep metric consistency with the uploaded image; if you switch metric, explain why.\n\n"
        f"Conversation summary: {summary or 'New conversation'}\n"
        f"Plan:\n{plan}"
    )

    mistral_messages = [{"role": "system", "content": system_prompt}]
    history_window = list(messages[-20:])
    # Mistral requires a tool role to follow an assistant tool_call message.
    # If truncation starts on a tool message, drop leading tools.
    while history_window and isinstance(history_window[0], ToolMessage):
        history_window.pop(0)
    if len(history_window) > 12:
        history_window = history_window[-12:]
    while history_window and isinstance(history_window[0], ToolMessage):
        history_window.pop(0)

    last_human_idx = None
    last_idx = len(history_window) - 1
    for idx, msg in enumerate(history_window):
        if isinstance(msg, HumanMessage):
            text = normalize_reply_content(msg.content)
            is_internal = is_internal_control_message(text)
            # Keep internal control prompts only when they are the immediate latest
            # message (active retry instruction). Otherwise they pollute future turns.
            if (not is_internal) or idx == last_idx:
                last_human_idx = idx

    for idx, msg in enumerate(history_window):
        if isinstance(msg, HumanMessage):
            text = normalize_reply_content(msg.content)
            is_internal = is_internal_control_message(text)
            if is_internal and idx != last_idx:
                continue
            if image_data and idx == last_human_idx:
                mistral_messages.append(
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": text},
                            {
                                "type": "image_url",
                                "image_url": f"data:image/jpeg;base64,{image_data}",
                            },
                        ],
                    }
                )
            else:
                mistral_messages.append({"role": "user", "content": text})
        elif isinstance(msg, AIMessage):
            ai_content = ""
            if msg.content is not None:
                ai_content = normalize_reply_content(msg.content)
                if ai_content == "(No text response)":
                    ai_content = ""

            tool_calls = msg.additional_kwargs.get("tool_calls", [])
            if tool_calls:
                formatted_tool_calls = []
                for tc in tool_calls:
                    formatted_tool_calls.append(
                        {
                            "id": tc.get("id", ""),
                            "type": "function",
                            "function": {
                                "name": tc.get("name", ""),
                                "arguments": tc.get("arguments", "{}"),
                            },
                        }
                    )
                mistral_messages.append(
                    {
                        "role": "assistant",
                        "content": ai_content,
                        "tool_calls": formatted_tool_calls,
                    }
                )
            else:
                mistral_messages.append({"role": "assistant", "content": ai_content})
        elif isinstance(msg, ToolMessage):
            mistral_messages.append(
                {
                    "role": "tool",
                    "content": normalize_reply_content(msg.content),
                    "tool_call_id": getattr(msg, "tool_call_id", ""),
                }
            )

    return mistral_messages


def agent_node(state: AgentState):
    messages = state["messages"]
    plan = state.get("plan", "")

    required_tools = list(dict.fromkeys(
        (state.get("required_tools") or []) + infer_required_tools_from_plan(plan)
    ))
    used_tools = set(used_tools_from_messages(messages))
    next_required_tool = next((tool for tool in required_tools if tool not in used_tools), None)
    tool_choice = (
        {"type": "function", "function": {"name": next_required_tool}}
        if next_required_tool
        else "auto"
    )

    mistral_messages = build_mistral_messages(state)

    stream = safe_chat_stream(
        model=MODEL,
        messages=mistral_messages,
        tools=tools,
        tool_choice=tool_choice,
        max_tokens=1024
    )
    content_text, tool_calls = collect_streamed_response(stream)

    if tool_calls:
        return {
            "messages": [
                AIMessage(
                    content=content_text,
                    additional_kwargs={"tool_calls": tool_calls},
                )
            ]
        }

    return {"messages": [AIMessage(content=content_text)]}


def tools_node(state: AgentState):
    last_message = state["messages"][-1]
    tool_calls = []
    if isinstance(last_message, AIMessage):
        tool_calls = last_message.additional_kwargs.get("tool_calls", [])
    if not tool_calls:
        return state

    tool_results = []
    for tool_call in tool_calls:
        result, plot_base64 = execute_tool_by_name_and_args(
            tool_call.get("name", ""),
            tool_call.get("arguments", "{}"),
        )
        tool_results.append(ToolMessage(
            content=result if (isinstance(result, str) and not result.startswith("Tool execution failed")) else "Tool unavailable - proceeding without this step.",
            tool_call_id=tool_call.get("id", ""),
            name=tool_call.get("name", ""),
            additional_kwargs={"plot_base64": plot_base64} if plot_base64 else {}
        ))

    return {"messages": tool_results}


def critic_node(state: AgentState):
    last_answer = state["messages"][-1].content
    retry_count = int(state.get("retry_count", 0))
    max_retries = 2
    normalized_last_answer = normalize_reply_content(last_answer)

    last_user_text = ""
    for msg in reversed(state["messages"]):
        if isinstance(msg, HumanMessage):
            candidate = normalize_reply_content(msg.content)
            if not is_internal_control_message(candidate):
                last_user_text = candidate
                break

    required_tools = list(dict.fromkeys(
        (state.get("required_tools") or []) + infer_required_tools_from_plan(state.get("plan", ""))
    ))
    used_tools = set(used_tools_from_messages(state["messages"]))
    web_search_used = "web_search" in used_tools
    missing_tools = [t for t in required_tools if t not in used_tools]
    extra_tools = [t for t in used_tools if t not in required_tools]
    is_pure_math = is_math_query(last_user_text) and set(required_tools) == {"calculator"}

    if is_pure_math:
        disallowed_tools_used = [t for t in used_tools if t in {"web_search", "code_interpreter"}]
        too_verbose = len(normalized_last_answer.split()) > 70
        if disallowed_tools_used or too_verbose:
            if retry_count >= max_retries:
                return {
                    "messages": [AIMessage(content=normalized_last_answer)],
                    "needs_retry": False,
                    "retry_count": retry_count,
                }
            retry_text = (
                "Revise the answer for a pure math query. Use only calculator and respond in 1-2 lines. "
                "Do not use web_search or code_interpreter."
            )
            if disallowed_tools_used:
                retry_text += f" Unnecessary tools were used: {', '.join(disallowed_tools_used)}."
            if too_verbose:
                retry_text += " The response was too long."
            return {
                "messages": [HumanMessage(content=retry_text)],
                "plan": state.get("plan", ""),
                "needs_retry": True,
                "retry_count": retry_count + 1,
            }

    if missing_tools:
        if retry_count >= max_retries:
            return {
                "messages": [
                    AIMessage(content=normalized_last_answer)
                ],
                "needs_retry": False,
                "retry_count": retry_count,
            }
        return {
            "messages": [
                HumanMessage(
                    content=(
                        "Continue and finish the remaining steps now. "
                        f"You must use these tools before finalizing: {', '.join(missing_tools)}."
                    )
                )
            ],
            "plan": state.get("plan", ""),
            "needs_retry": True,
            "retry_count": retry_count + 1,
        }

    if extra_tools and not required_tools:
        if retry_count >= max_retries:
            return {
                "messages": [AIMessage(content=normalized_last_answer)],
                "needs_retry": False,
                "retry_count": retry_count,
            }
        return {
            "messages": [
                HumanMessage(
                    content=(
                        "Revise with minimal tool usage. You used unnecessary tools: "
                        f"{', '.join(extra_tools)}. Re-answer concisely and only use tools if strictly needed."
                    )
                )
            ],
            "plan": state.get("plan", ""),
            "needs_retry": True,
            "retry_count": retry_count + 1,
        }

    if (not web_search_used) and (
        re.search(r"https?://", normalized_last_answer, re.IGNORECASE)
        or "reference_ids=" in normalized_last_answer
    ):
        if retry_count >= max_retries:
            return {
                "messages": [AIMessage(content=normalized_last_answer)],
                "needs_retry": False,
                "retry_count": retry_count,
            }
        return {
            "messages": [
                HumanMessage(
                    content=(
                        "Revise the answer and remove external links/references. "
                        "web_search was not used, so do not cite web sources. "
                        "Provide the final answer directly without labels."
                    )
                )
            ],
            "plan": state.get("plan", ""),
            "needs_retry": True,
            "retry_count": retry_count + 1,
        }

    has_image = bool(state.get("image_data"))
    tool_criteria = (
        "2. Were required tools used appropriately? (Note: pure image description needs NO tools)"
        if has_image and not state.get("required_tools")
        else "2. Were ALL required tools used? (Only: calculator, web_search, code_interpreter)"
    )

    critic_prompt = f"""Review this answer: {normalized_last_answer}
Criteria:
1. Did it follow the plan reasonably?
{tool_criteria}
3. Were tools used appropriately and minimally? Unnecessary tools are a failure.
4. Is the answer concise for the request type (simple math should be 1-2 lines)?
5. Is the answer accurate and well-reasoned? If data was unavailable, did it say so honestly?
6. Did it correctly analyze the image if one was provided?
7. Do NOT fail an answer just because it did not explicitly list tool names.
8. Only require source links if web_search tool was actually used in this run.
Never flag fake or invented tool names as valid tool usage.
If ANY criterion clearly fails -> say "NEEDS IMPROVEMENT" + explain.
Otherwise say "GOOD".
web_search_used={web_search_used}"""

    critique = safe_chat_complete(
        model=CRITIC_MODEL,
        messages=[{"role": "user", "content": critic_prompt}],
        max_tokens=300
    ).choices[0].message.content

    if "GOOD" in critique.upper():
        return {
            "messages": [],
            "needs_retry": False,
            "retry_count": retry_count,
        }

    if retry_count >= max_retries:
        return {
            "messages": [AIMessage(content=normalized_last_answer)],
            "needs_retry": False,
            "retry_count": retry_count,
        }
    return {
        "messages": [
            HumanMessage(
                content=(
                    "Revise and improve the previous answer based on this critique, "
                    "then continue execution if any planned step is incomplete. "
                    "Provide the final answer directly without headings like 'Revised Answer':\n"
                    f"{critique}"
                )
            )
        ],
        "plan": state.get("plan", ""),
        "needs_retry": True,
        "retry_count": retry_count + 1,
    }


def summarize_memory(state: AgentState):
    messages = state["messages"]
    readable = []
    for m in messages[-5:]:
        if isinstance(m, HumanMessage):
            text = normalize_reply_content(m.content)
            if not is_internal_control_message(text):
                readable.append(f"User: {text}")
        elif isinstance(m, AIMessage):
            readable.append(f"Assistant: {normalize_reply_content(m.content)}")

    summary_prompt = "Summarize key points in 2-3 sentences:\n" + "\n".join(readable)

    summary = safe_chat_complete(
        model=MODEL,
        messages=[
            {"role": "system", "content": "You are a helpful summarizer."},
            {"role": "user", "content": summary_prompt},
        ],
        max_tokens=150
    ).choices[0].message.content

    return {"summary": summary}


workflow = StateGraph(AgentState)
workflow.add_node("planner", planner_node)
workflow.add_node("agent", agent_node)
workflow.add_node("tools", tools_node)
workflow.add_node("critic", critic_node)
workflow.add_node("summarize", summarize_memory)

workflow.set_entry_point("planner")
workflow.add_edge("planner", "agent")
workflow.add_conditional_edges(
    "agent",
    lambda s: "tools" if isinstance(s["messages"][-1], AIMessage) and s["messages"][-1].additional_kwargs.get("tool_calls") else "critic"
)
workflow.add_edge("tools", "agent")
workflow.add_conditional_edges(
    "critic",
    lambda s: "agent" if s.get("needs_retry") else "summarize"
)
workflow.add_edge("summarize", END)

app = workflow.compile()
