import os
import base64
import warnings
import traceback
from io import BytesIO
from PIL import Image
import gradio as gr
from mistralai import Mistral

import json
import math
import re
import io
import contextlib
import logging
import subprocess
import httpx
try:
    from ddgs import DDGS
except ImportError:
    from duckduckgo_search import DDGS

from dotenv import load_dotenv

from typing import Annotated, Sequence, TypedDict
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate
from mistralai import Mistral  # your existing client


load_dotenv()
api_key = (os.getenv("MISTRAL_API_KEY") or "").strip().strip('"').strip("'")
if not api_key:
    raise ValueError("MISTRAL_API_KEY not found in .env")

warnings.filterwarnings(
    "ignore",
    message=".*HTTP_422_UNPROCESSABLE_ENTITY.*",
    category=DeprecationWarning,
)
warnings.filterwarnings(
    "ignore",
    message=".*duckduckgo_search.*has been renamed to `ddgs`.*",
    category=RuntimeWarning,
)
warnings.filterwarnings(
    "ignore",
    message=".*FigureCanvasAgg is non-interactive, and thus cannot be shown.*",
    category=UserWarning,
)
logging.getLogger("primp").setLevel(logging.ERROR)
logging.getLogger("ddgs").setLevel(logging.ERROR)

SANDBOX_TIMEOUT_SECONDS = 12

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    summary: str  # Conversation memory summary
    image_data: str  # Base64 image if present (persistent across turns)
    plan: str  # Current plan (generated by planner)
    needs_retry: bool  # Whether execution should continue before finalizing
    retry_count: int  # Loop guard for critic->agent retries
    required_tools: list[str]  # Required tools inferred from the original user request


client = Mistral(api_key=api_key)

MODEL = "pixtral-large-latest"

planner_prompt = ChatPromptTemplate.from_template(
    """You are a helpful multimodal agent. Given the user query and any image context, create a clear step-by-step plan.
    Use tools only when necessary (calculator for math, web_search for facts, code_interpreter for execution).
    If the query asks for recent data, trends, or benchmarks, ALWAYS use web_search first.
    If the query is simple, just answer directly.
    
    Current conversation summary: {summary}
    User query: {query}
    
    Output ONLY the plan as numbered steps.""")

# Tool schemas — Mistral expects OpenAI-compatible format
tools = [
    {
        "type": "function",
        "function": {
            "name": "calculator",
            "description": "Evaluate a math expression safely. Use for calculations, especially from images/charts.",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {"type": "string", "description": "Math expression, e.g. 'sin(pi/2) + 3 * 4'"}
                },
                "required": ["expression"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "web_search",
            "description": "Search the web for facts, current events, or info not in your knowledge.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search query"}
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "code_interpreter",
            "description": "Execute simple Python code and return output. Use for plotting, math, or analysis.",
            "parameters": {
                "type": "object",
                "properties": {
                    "code": {"type": "string", "description": "Python code snippet"}
                },
                "required": ["code"]
            }
        }
    }
]



def planner_node(state: AgentState):
    summary = state.get("summary", "New conversation")
    query = state["messages"][-1].content if state["messages"] else ""
    if isinstance(query, list):
        query = normalize_reply_content(query)

    planning_text = (
        "You are a helpful multimodal agent. Given the user query and any image context, "
        "create a clear step-by-step plan. Use tools only when necessary (calculator for math, "
        "web_search for facts, code_interpreter for execution). If the query asks for recent data, trends, or benchmarks, "
        "ALWAYS use web_search first. If the query is simple, just answer directly.\n\n"
        f"Conversation summary: {summary or 'New conversation'}\n"
        f"User query: {query}\n\n"
        "Output ONLY the plan as numbered steps."
    )
    try:
        plan = safe_chat_complete(
            model=MODEL,
            messages=[{"role": "user", "content": planning_text}],
            max_tokens=300,
            temperature=0.2,
        ).choices[0].message.content
        plan = normalize_reply_content(plan)
    except Exception:
        plan = (
            "1. Analyze image trends.\n"
            "2. Use web_search for recent/similar data.\n"
            "3. Use code_interpreter to produce and verify improved visualization.\n"
            "4. Summarize findings with tool evidence."
        )

    return {"plan": plan}

def infer_required_tools(query_text: str):
    t = (query_text or "").lower()
    required = []
    if any(k in t for k in ["search", "recent data", "latest", "similar data"]):
        required.append("web_search")
    if any(k in t for k in ["code", "visualization", "plot", "verify", "run"]):
        required.append("code_interpreter")
    if is_math_query(t):
        required.append("calculator")
    return required

def infer_required_tools_from_plan(plan_text: str):
    p = (plan_text or "").lower()
    required = []
    if "web_search" in p or ("search" in p and "recent" in p):
        required.append("web_search")
    if "code_interpreter" in p or any(k in p for k in ["code", "visualization", "plot", "verify", "run"]):
        required.append("code_interpreter")
    if "calculator" in p or any(k in p for k in ["integral", "derivative", "equation", "calculate"]):
        required.append("calculator")
    return required


def used_tools_from_messages(messages):
    used = []
    for msg in messages:
        if isinstance(msg, ToolMessage):
            name = getattr(msg, "name", "")
            if name:
                used.append(name)
    return used


def agent_node(state: AgentState):
    messages = state["messages"]
    plan = state.get("plan", "")
    summary = state.get("summary", "")
    latest_query = ""
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            latest_query = str(msg.content)
            break

    required_tools = list(dict.fromkeys(
        (state.get("required_tools") or []) + infer_required_tools_from_plan(plan)
    ))
    used_tools = set(used_tools_from_messages(messages))
    next_required_tool = next((tool for tool in required_tools if tool not in used_tools), None)
    tool_choice = (
        {"type": "function", "function": {"name": next_required_tool}}
        if next_required_tool
        else "auto"
    )

    convo_lines = []
    for msg in messages[-12:]:
        if isinstance(msg, HumanMessage):
            convo_lines.append(f"User: {msg.content}")
        elif isinstance(msg, AIMessage):
            convo_lines.append(f"Assistant: {msg.content}")
        elif isinstance(msg, ToolMessage):
            convo_lines.append(f"Tool({getattr(msg, 'name', '')}): {msg.content}")

    prompt = (
        "You MUST follow the plan step-by-step. Do not skip or combine steps unless explicitly allowed.\n"
        "Follow the plan and complete the task end-to-end in this turn. "
        "Do not say you will do a step later; either do it now with tool calls or explain the concrete tool error.\n"
        "Do not print raw tool-call JSON in your final answer.\n"
        "If an image is attached, do not claim the image is unavailable; analyze it directly.\n"
        "If asked to analyze trends, include a concise trend analysis. "
        "If asked to search recent/similar data, perform web_search and cite key findings. "
        "If asked to code and verify, run code_interpreter and report execution status.\n\n"
        "Never invent or reference tools that don't exist. "
        "Available tools are ONLY: calculator, web_search, code_interpreter. "
        "For image description, use your vision capabilities directly — no tools needed.\n\n"
        "CRITICAL: Never use hypothetical, placeholder, or made-up data. "
        "If a tool returns no usable data, say so explicitly and stop. "
        "Do not proceed with fabricated numbers.\n\n"
        "Output requirements for final answer:\n"
        "1) If web_search was used, include source links from tool output.\n"
        "2) Keep metric consistency with the uploaded image; if you switch metric, explain why.\n\n"
        f"Conversation summary: {summary or 'New conversation'}\n"
        f"Plan:\n{plan}\n\nConversation:\n" + "\n".join(convo_lines)
    )
    content = [{"type": "text", "text": prompt}]
    if state.get("image_data"):
        content.append(
            {
                "type": "image_url",
                "image_url": f"data:image/jpeg;base64,{state['image_data']}"
            }
        )
    mistral_messages = [{"role": "user", "content": content}]

    response = safe_chat_complete(
        model=MODEL,
        messages=mistral_messages,
        tools=tools,
        tool_choice=tool_choice,
        max_tokens=1024
    )

    choice = response.choices[0].message
    if getattr(choice, "tool_calls", None):
        lc_tool_calls = []
        for tc in choice.tool_calls:
            lc_tool_calls.append(
                {
                    "id": tc.id,
                    "name": tc.function.name,
                    "arguments": tc.function.arguments if isinstance(tc.function.arguments, str) else json.dumps(tc.function.arguments),
                }
            )
        return {
            "messages": [
                AIMessage(
                    content=normalize_reply_content(choice.content),
                    additional_kwargs={"tool_calls": lc_tool_calls},
                )
            ]
        }

    return {"messages": [AIMessage(content=normalize_reply_content(choice.content))]}

def tools_node(state: AgentState):
    last_message = state["messages"][-1]
    tool_calls = []
    if isinstance(last_message, AIMessage):
        tool_calls = last_message.additional_kwargs.get("tool_calls", [])
    if not tool_calls:
        return state

    tool_results = []
    for tool_call in tool_calls:
        result, plot_base64 = execute_tool_by_name_and_args(
            tool_call.get("name", ""),
            tool_call.get("arguments", "{}"),
        )
        tool_results.append(ToolMessage(
            content=result if (isinstance(result, str) and not result.startswith("Tool execution failed")) else "Tool unavailable — proceeding without this step.",
            tool_call_id=tool_call.get("id", ""),
            name=tool_call.get("name", ""),
            additional_kwargs={"plot_base64": plot_base64} if plot_base64 else {}
        ))

    return {"messages": tool_results}

def critic_node(state: AgentState):
    last_answer = state["messages"][-1].content
    retry_count = int(state.get("retry_count", 0))
    max_retries = 2  # reduced from 6
    latest_query = ""
    for msg in reversed(state["messages"]):
        if isinstance(msg, HumanMessage):
            latest_query = str(msg.content)
            break

    required_tools = list(dict.fromkeys(
        (state.get("required_tools") or []) + infer_required_tools_from_plan(state.get("plan", ""))
    ))
    used_tools = set(used_tools_from_messages(state["messages"]))
    missing_tools = [t for t in required_tools if t not in used_tools]
    if missing_tools:
        if retry_count >= max_retries:
            return {
                "messages": [
                    AIMessage(content=last_answer)  # silently stop, no debug text
                ],
                "needs_retry": False,
                "retry_count": retry_count,
            }
        return {
            "messages": [
                HumanMessage(
                    content=(
                        "Continue and finish the remaining steps now. "
                        f"You must use these tools before finalizing: {', '.join(missing_tools)}."
                    )
                )
            ],
            "plan": f"Continue execution and use remaining tools before final answer: {', '.join(missing_tools)}.",
            "needs_retry": True,
            "retry_count": retry_count + 1,
        }

    # Context-aware tool criteria
    has_image = bool(state.get("image_data"))
    tool_criteria = (
        "2. Were required tools used appropriately? (Note: pure image description needs NO tools)"
        if has_image and not state.get("required_tools")
        else "2. Were ALL required tools used? (Only: calculator, web_search, code_interpreter)"
    )

    critic_prompt = f"""Review this answer: {last_answer}
Criteria:
1. Did it follow the plan reasonably?
{tool_criteria}
3. Is the answer accurate and well-reasoned? If data was unavailable, did it say so honestly?
4. Did it correctly analyze the image if one was provided?
Never flag fake or invented tool names as valid tool usage.
If ANY criterion clearly fails -> say "NEEDS IMPROVEMENT" + explain.
Otherwise say "GOOD"."""

    critique = safe_chat_complete(
        model=MODEL,
        messages=[{"role": "user", "content": critic_prompt}],
        max_tokens=300
    ).choices[0].message.content

    if "GOOD" in critique.upper():
        return {
            "messages": [AIMessage(content=last_answer)],  # no [Critique: Passed] leak
            "needs_retry": False,
            "retry_count": retry_count,
        }
    else:
        if retry_count >= max_retries:
            return {
                "messages": [AIMessage(content=last_answer)],  # silently stop
                "needs_retry": False,
                "retry_count": retry_count,
            }
        return {
            "messages": [
                HumanMessage(
                    content=(
                        "Revise and improve the previous answer based on this critique, "
                        "then continue execution if any planned step is incomplete:\n"
                        f"{critique}"
                    )
                )
            ],
            "plan": f"Revise and fix: {critique}",
            "needs_retry": True,
            "retry_count": retry_count + 1,
        }
def summarize_memory(state: AgentState):
    messages = state["messages"]
    summary_prompt = f"Summarize key points from this conversation in 2-3 sentences:\n{messages[-5:]}"

    summary = safe_chat_complete(
        model=MODEL,
        messages=[{"role": "user", "content": summary_prompt}],
        max_tokens=150
    ).choices[0].message.content
    
    return {"summary": summary}


# Build graph
workflow = StateGraph(AgentState)

workflow.add_node("planner", planner_node)
workflow.add_node("agent", agent_node)
workflow.add_node("tools", tools_node)
workflow.add_node("critic", critic_node)
workflow.add_node("summarize", summarize_memory)

# Edges
workflow.set_entry_point("planner")
workflow.add_edge("planner", "agent")
workflow.add_conditional_edges(
    "agent",
    lambda s: "tools" if isinstance(s["messages"][-1], AIMessage) and s["messages"][-1].additional_kwargs.get("tool_calls") else "critic"
)
workflow.add_edge("tools", "agent")  # Loop back after tools
workflow.add_conditional_edges(
    "critic",
    lambda s: "agent" if s.get("needs_retry") else "summarize"
)
workflow.add_edge("summarize", END)

app = workflow.compile()


def safe_chat_complete(**kwargs):
    try:
        return client.chat.complete(**kwargs)
    except (httpx.ConnectTimeout, httpx.ReadTimeout, TimeoutError):
        raise RuntimeError("Network timeout while contacting Mistral API. Please retry in a few seconds.")
    except Exception as e:
        # Keep original behavior for non-timeout errors.
        raise RuntimeError(f"Mistral API request failed: {e}")


def run_code_in_sandbox(user_code, timeout_seconds=12):
    payload = json.dumps(user_code)
    sandbox_script = f"""
import io, contextlib, traceback, base64, json, os, time, pathlib
user_code = {payload}
sanitized_code = user_code.replace("plt.show()", "").replace("matplotlib.pyplot.show()", "")
stdout_buffer = io.StringIO()
local = {{"os": os, "time": time, "pathlib": pathlib}}
allowed_roots = {{"math","statistics","numpy","matplotlib","seaborn","pandas","os","time","pathlib"}}
real_import = __import__
def safe_import(name, globals=None, locals=None, fromlist=(), level=0):
    root = name.split(".")[0]
    if root not in allowed_roots:
        raise ImportError(f"Import '{{name}}' is blocked in sandbox.")
    return real_import(name, globals, locals, fromlist, level)
safe_builtins = {{
    "__import__": safe_import,
    "print": print,
    "range": range,
    "len": len,
    "sum": sum,
    "min": min,
    "max": max,
    "abs": abs,
    "round": round,
    "int": int,
    "float": float,
    "str": str,
    "list": list,
    "dict": dict,
    "set": set,
    "tuple": tuple,
    "enumerate": enumerate,
    "zip": zip,
}}
try:
    with contextlib.redirect_stdout(stdout_buffer):
        exec(sanitized_code, {{"__builtins__": safe_builtins}}, local)
    output = stdout_buffer.getvalue().strip() or local.get("result", "Executed (no output)")
    plot_base64 = None
    if "plt" in user_code.lower() or "matplotlib" in user_code.lower():
        try:
            import matplotlib.pyplot as plt
            buf = io.BytesIO()
            plt.savefig(buf, format="png", bbox_inches="tight")
            buf.seek(0)
            plot_base64 = base64.b64encode(buf.read()).decode("utf-8")
        except Exception:
            pass
        finally:
            try:
                plt.close("all")
            except Exception:
                pass
    print("SANDBOX_RESULT:" + json.dumps({{"ok": True, "text": "Code output:\\n" + str(output), "plot_base64": plot_base64}}))
except Exception:
    print("SANDBOX_RESULT:" + json.dumps({{"ok": False, "text": "Code error:\\n" + traceback.format_exc(limit=2), "plot_base64": None}}))
"""
    try:
        completed = subprocess.run(
            ["py", "-3.11", "-c", sandbox_script],
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
        )
    except subprocess.TimeoutExpired:
        return "Code error: sandbox timeout after {0} seconds.".format(timeout_seconds), None
    except Exception as e:
        return f"Code error: sandbox launch failed: {e}", None

    lines = (completed.stdout or "").splitlines()
    for line in reversed(lines):
        if line.startswith("SANDBOX_RESULT:"):
            try:
                result = json.loads(line[len("SANDBOX_RESULT:"):])
                return result.get("text", "Code error: unknown sandbox output."), result.get("plot_base64")
            except Exception:
                break
    if completed.stderr:
        return "Code error:\n" + completed.stderr.strip(), None
    return "Code error: sandbox terminated without parsable output.", None

def execute_tool(tool_call):
    """Run the tool and return string result"""
    if not tool_call or not tool_call.function:
        return "No tool call found."

    name = tool_call.function.name
    try:
        raw_args = tool_call.function.arguments
        return execute_tool_by_name_and_args(name, raw_args)
    except Exception:
        return "Invalid tool arguments."


def execute_tool_by_name_and_args(name, raw_args):
    try:
        args = json.loads(raw_args) if isinstance(raw_args, str) else raw_args
        if not isinstance(args, dict):
            return "Invalid tool arguments.", None
    except Exception:
        return "Invalid tool arguments.", None

    try:
        if name == "calculator":
            safe_dict = {k: v for k, v in math.__dict__.items() 
                        if not k.startswith("_") and callable(v) or isinstance(v, (int, float))}
            safe_dict["__builtins__"] = {}
            result = eval(args["expression"], safe_dict)
            return f"Calculation result: {result}", None

        elif name == "web_search":
            with contextlib.redirect_stderr(io.StringIO()), contextlib.redirect_stdout(io.StringIO()):
                with DDGS() as ddgs:
                    results = [r for r in ddgs.text(args["query"], max_results=3)]
            if not results:
                return f"web_search(query={args.get('query', '')}) -> No relevant results found.", None
            summaries = [f"- {r['title']}: {r['body'][:300]}... Source: {r['href']}" for r in results]
            return f"web_search(query={args.get('query', '')}) results:\n" + "\n".join(summaries), None

        elif name == "code_interpreter":
            user_code = args.get("code", "")
            if not isinstance(user_code, str) or not user_code.strip():
                return "Code error: missing 'code' string.", None
            return run_code_in_sandbox(user_code, timeout_seconds=SANDBOX_TIMEOUT_SECONDS)

        else:
            return "Unknown tool.", None
    except Exception as e:
        return f"Tool execution failed: {str(e)}", None


def encode_image(image_pil):
    buffered = BytesIO()
    image_pil.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

def normalize_reply_content(content):
    if isinstance(content, str):
        return content
    if isinstance(content, list):
        parts = []
        for item in content:
            if isinstance(item, dict) and item.get("type") == "text":
                parts.append(item.get("text", ""))
            else:
                parts.append(str(item))
        return "\n".join([p for p in parts if p]).strip() or "(No text response)"
    return str(content)

def is_math_query(text):
    if not text:
        return False
    t = text.lower()
    math_keywords = [
        "integral", "differentiate", "derivative", "equation", "solve",
        "simplify", "factor", "limit", "matrix", "algebra", "calculate", "compute"
    ]
    if any(k in t for k in math_keywords):
        return True
    return bool(re.search(r"[\d\)\]]\s*[\+\-\*/\^]\s*[\d\(\[]", t))


def multimodal_chat(image, text, api_history):
    messages = api_history.copy() if api_history else []
    reply = "No final response generated."

    current_content = [{"type": "text", "text": text or "Describe this image in detail."}]
    if image is not None:
        base64_img = encode_image(image)
        current_content.append({
            "type": "image_url",
            "image_url": f"data:image/jpeg;base64,{base64_img}"
        })

    messages.append({"role": "user", "content": current_content})

    force_calculator_for_math = is_math_query(text)
    tool_choice = (
        {"type": "function", "function": {"name": "calculator"}}
        if force_calculator_for_math
        else "auto"
    )
    max_tool_rounds = 3  # Prevent infinite loops
    for round in range(max_tool_rounds):
        try:
            response = client.chat.complete(
                model=MODEL,
                messages=messages,
                tools=tools,
                tool_choice=tool_choice,
                max_tokens=1024,
                temperature=0.7
            )
            choice = response.choices[0]

            if choice.finish_reason == "tool_calls" and choice.message.tool_calls:
                # Add assistant tool-call message once, then add one tool result per call.
                messages.append(choice.message.model_dump(exclude_none=True))
                for tool_call in choice.message.tool_calls:
                    tool_result = execute_tool(tool_call)
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": tool_call.function.name,
                        "content": tool_result
                    })
            else:
                # Normal reply — done
                reply = normalize_reply_content(choice.message.content)
                messages.append({"role": "assistant", "content": reply})
                break

        except Exception as e:
            reply = f"API Error in round {round+1}: {str(e)}"
            messages.append({"role": "assistant", "content": reply})
            break

    # If every round used tools, run one final pass to produce plain assistant text.
    if reply == "No final response generated.":
        try:
            final_response = client.chat.complete(
                model=MODEL,
                messages=messages,
                max_tokens=1024,
                temperature=0.7
            )
            final_choice = final_response.choices[0]
            reply = normalize_reply_content(final_choice.message.content)
            messages.append({"role": "assistant", "content": reply})
        except Exception as e:
            reply = f"API Error after tools: {str(e)}"
            messages.append({"role": "assistant", "content": reply})

    return messages, reply

# Gradio UI
with gr.Blocks(title="Pixtral Multimodal Agent") as demo:
    gr.Markdown("# Pixtral Multimodal Agent\nUpload image + ask anything about it!")
    
    with gr.Row():
        with gr.Column(scale=2):
            chatbot = gr.Chatbot(height=500, label="Conversation")
        with gr.Column(scale=1):
            plan_display = gr.Textbox(label="Current Agent Plan", interactive=False, lines=10)
            summary_display = gr.Textbox(label="Conversation Summary", interactive=False, lines=5)
            plot_display = gr.Image(label="Generated Plot", type="pil")
    
    msg = gr.Textbox(placeholder="Ask about the image (e.g., 'What trends do you see here?')", label="Your question")
    img_input = gr.Image(type="pil", label="Upload Image (JPEG/PNG)")
    clear = gr.Button("Clear Conversation")

    api_state = gr.State([])
    chat_state = gr.State([])
    summary_state = gr.State("")

    def respond(message, image, api_history, ui_history, running_summary):
        original_required_tools = infer_required_tools(message or "")
        inputs = {
            "messages": (api_history or []) + [HumanMessage(content=message or "")],
            "summary": running_summary or "",
            "image_data": "",
            "plan": "",
            "needs_retry": False,
            "retry_count": 0,
            "required_tools": original_required_tools,
        }
        if image is not None:
            inputs["image_data"] = encode_image(image)

        try:
            result = app.invoke(inputs, config={"recursion_limit": 80})
        except Exception as e:
            error_reply = f"Temporary failure: {e}"
            new_ui_history = (ui_history or []) + [
                {"role": "user", "content": message or ""},
                {"role": "assistant", "content": error_reply},
            ]
            return "", api_history or [], new_ui_history, new_ui_history, running_summary or "", "", None

        final_reply = normalize_reply_content(result["messages"][-1].content)

        # Strip internal critic/debug annotations before showing to user
        final_reply = re.sub(r'\n?\[Critique:.*?\)]', '', final_reply, flags=re.DOTALL)
        final_reply = re.sub(r'\n?Stopped after retry limit.*', '', final_reply, flags=re.DOTALL)
        final_reply = re.sub(r'\[\{\"name\".*?\}\]', '', final_reply, flags=re.DOTALL)
        final_reply = re.sub(r'\[?\{\"name\": \"code_interpreter\".*', '', final_reply, flags=re.DOTALL)
        new_api_history = result["messages"]
        new_summary = result.get("summary", running_summary or "")
        new_ui_history = (ui_history or []) + [
            {"role": "user", "content": message or ""},
            {"role": "assistant", "content": final_reply},
        ]
        
        # Extract plot if available from tool messages
        plot_image = None
        for msg_obj in new_api_history:
            if isinstance(msg_obj, ToolMessage):
                plot_b64 = msg_obj.additional_kwargs.get("plot_base64")
                if plot_b64:
                    try:
                        import base64
                        img_data = base64.b64decode(plot_b64)
                        plot_image = Image.open(BytesIO(img_data))
                        break
                    except Exception:
                        pass
        
        return "", new_api_history, new_ui_history, new_ui_history, new_summary, result.get("plan", ""), plot_image

    msg.submit(
        respond,
        inputs=[msg, img_input, api_state, chat_state, summary_state],
        outputs=[msg, api_state, chat_state, chatbot, summary_state, plan_display, plot_display]
    )
    
    clear.click(
        lambda: ("", [], [], [], "", "", None),
        None,
        [msg, api_state, chat_state, chatbot, summary_state, plan_display, plot_display]
    )

demo.launch(share=False)
